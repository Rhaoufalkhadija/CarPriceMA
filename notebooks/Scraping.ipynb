{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecte de données(WebScraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Send HTTP requests to fetch web page content\n",
    "from bs4 import BeautifulSoup  # Parse and extract data from HTML content\n",
    "import tqdm.notebook as tqdm  # Display progress bars in Jupyter notebooks\n",
    "import time  # Manage delays between requests\n",
    "import pandas as pd  # Work with data in DataFrame format\n",
    "import random  # Add delays between requests to avoid being blocked\n",
    "import json  # Work with JSON data (save/load structured data)\n",
    "import tqdm  # General tqdm for progress bars in scripts or terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f784ba2855a3441b9ceccbc330296977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'annonces collectées: 11108\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "listing_urls = set()\n",
    "\n",
    "for i in tqdm.trange(500):  # trange = range loop with progress bar\n",
    "    url = f'https://www.avito.ma/fr/maroc/voitures_d_occasion-%C3%A0_vendre?o={i+1}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code} while accessing {url}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for a in soup.select('div.listing>a'):\n",
    "        price_tag = a.select_one('p.dJAfqm.eTHoJR')\n",
    "        if not price_tag or price_tag.get_text() == \"Prix non spécifié\":\n",
    "            continue\n",
    "\n",
    "        href = a.get('href')\n",
    "        if href:\n",
    "            listing_urls.add(href)\n",
    "\n",
    "    time.sleep(random.uniform(1, 3))  # Pause to avoid getting blocked\n",
    "\n",
    "print(f\"Nombre total d'annonces collectées: {len(listing_urls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 8727/11108 [54:40<14:11,  2.80it/s]     "
     ]
    }
   ],
   "source": [
    "# Initialize the dataset list\n",
    "dataset = []\n",
    "\n",
    "# Iterate over the listing URLs\n",
    "for url in tqdm.tqdm(listing_urls):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Dictionary to store information for each car\n",
    "    entry = {}\n",
    "\n",
    "    # Extract price\n",
    "    prix_elem = soup.select_one(\"p.lnEFFR\")\n",
    "    entry[\"Prix\"] = prix_elem.get_text(strip=True) if prix_elem else None\n",
    "\n",
    "    # Main attribute keys\n",
    "    attribute_keys = [\n",
    "        \"Année\", \"BoiteàV\", \"Carburant\", \"kilometrage\", \"Marque\", \"Model\", \n",
    "        \"NBporte\", \"Origine\", \"Première main\", \"Puissance fiscale\", \"Etat\"\n",
    "    ]\n",
    "\n",
    "    # Extract attribute values\n",
    "    divs = soup.select('div.sc-19cngu6-1.doRGIC')\n",
    "    attribute_values = set()  \n",
    "    \n",
    "    for i, attribute_key in enumerate(attribute_keys):\n",
    "        if i < len(divs):\n",
    "            value_elem = divs[i].select_one('span.fjZBup')\n",
    "            value = value_elem.get_text(strip=True) if value_elem else None\n",
    "            entry[attribute_key] = value\n",
    "            if value:\n",
    "                attribute_values.add(value) \n",
    "            entry[attribute_key] = None  # Reset the value (probably by mistake)\n",
    "\n",
    "    # Get all spans containing features and attributes\n",
    "    all_values = {\n",
    "        span.get_text(strip=True)\n",
    "        for span in soup.select('div.sc-19cngu6-1.doRGIC span.fjZBup')\n",
    "    }\n",
    "\n",
    "    # Remove values already used as attributes\n",
    "    equipements = list(all_values - attribute_values)\n",
    "\n",
    "    # Convert features to JSON format (clean list representation)\n",
    "    entry['équipements'] = json.dumps(equipements)\n",
    "\n",
    "    # Add entry to the dataset\n",
    "    dataset.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Sauvegarder les données sous forme de CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = pd.DataFrame(\u001b[43mdataset\u001b[49m)\n\u001b[32m      3\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mavito_pfm2.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the data to a CSV file\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv('avito_pfm2.csv', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
